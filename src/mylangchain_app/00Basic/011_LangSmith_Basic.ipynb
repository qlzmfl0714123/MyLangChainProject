{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "#### LangSmith 기본 예제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "##### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "##### 2) OpenAI 인증키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_b\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "##### LangSmith와 LangChain을 활용한 기본 로깅 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 [AI 답변]:\n",
      "LangGraph와 LangChain은 모두 언어 모델을 활용하여 애플리케이션을 구축하기 위한 프레임워크이지만, 서로 다른 디자인 철학과 사용 사례에 중점을 둡니다.\n",
      "\n",
      "LangChain은 언어 모델을 중심으로 다양한 외부 리소스(예: API, 데이터베이스 등)를 연결하여 보다 복잡한 애플리케이션을 구축할 수 있는 프레임워크입니다. LangChain은 프롬프트 체이닝, 메모리, API 통합과 같은 기능을 제공하여 개발자가 언어 모델을 활용하여 애플리케이션을 쉽게 구축할 수 있도록 지원합니다.\n",
      "\n",
      "LangGraph는 LangChain의 최신 모듈로, 여러 언어 모델 또는 언어 모델과 자체 AI 에이전트 간의 워크플로를 구축하는 데 특화되어 있습니다. LangGraph를 사용하면 여러 AI 모델을 연결하여 복잡한 멀티모델 워크플로를 만들 수 있습니다.\n",
      "\n",
      "즉, LangChain이 더 넓은 범위의 애플리케이션에 활용될 수 있는 반면, LangGraph는 여러 AI 모델을 연결하여 복잡한 워크플로를 구축하는 데 특화되어 있다고 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langsmith import traceable\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# LangSmith API Key 설정\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")  # LangSmith 활성화\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")  # API Key 불러오기\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")   # 프로젝트 이름 설정\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")   # EndPoint 설정\n",
    "\n",
    "# LLM 모델 설정 (OpenAI 사용)\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# LangSmith로 실행 추적\n",
    "@traceable(run_type=\"chain\", name=\"Simple_Chain\")\n",
    "def ask_question(question: str):\n",
    "\n",
    "    # 개별 메시지 템플릿 정의\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 유용한 AI 비서입니다.\"\n",
    "    )\n",
    "    user_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ])\n",
    "    \n",
    "    messages = chat_prompt.format_messages(question=question)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# 테스트 실행\n",
    "question = \"LangGraph와 LangChain의 차이점은 무엇인가요?\"\n",
    "answer = ask_question(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n🔹 [AI 답변]:\")\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
