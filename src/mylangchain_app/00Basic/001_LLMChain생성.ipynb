{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_8\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델은 다양한 데이터를 수집하여 학습합니다. 이 데이터는 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다.\\n2.  **데이터 전처리**: 수집된 데이터는 전처리 과정을 거칩니다. 이 과정에서는 데이터를 정제하고, 필요한 경우 데이터를 변환하거나 축소하는 작업을 수행합니다.\\n3.  **모델 초기화**: 인공지능 모델은 초기화 과정을 거칩니다. 이 과정에서는 모델의 가중치와 편향이 초기화됩니다.\\n4.  **학습**: 인공지능 모델은 학습 데이터를 사용하여 학습합니다. 이 과정에서는 모델이 데이터를 분석하고, 패턴을 학습하며, 가중치와 편향을 업데이트합니다.\\n5.  **평가**: 학습이 완료되면, 인공지능 모델은 평가 데이터를 사용하여 평가됩니다. 이 과정에서는 모델의 성능을 측정하고, 필요한 경우 모델을 조정합니다.\\n\\n예를 들어, 이미지 분류 모델을 학습하는 경우를 생각해 봅시다. 이 모델은 다양한 이미지 데이터를 수집하여 학습합니다. 이 데이터는 고양이, 강아지, 자동차 등 다양한 객체를 포함할 수 있습니다. 모델은 이 데이터를 분석하여 각 객체를 분류하는 법을 학습합니다. 학습이 완료되면, 모델은 새로운 이미지를 분류할 수 있습니다.\\n\\n인공지능 모델의 학습 원리는 다음과 같은 핵심 개념을 포함합니다.\\n\\n*   **오차**: 모델의 예측과 실제 값 사이의 차이입니다.\\n*   **손실 함수**: 모델의 성능을 측정하는 함수입니다. 손실 함수는 오차를 최소화하는 것을 목표로 합니다.\\n*   **최적화 알고리즘**: 모델의 가중치와 편향을 업데이트하는 알고리즘입니다. 최적화 알고리즘은 손실 함수를 최소화하는 것을 목표로 합니다.\\n\\n인공지능 모델의 학습 원리는 복잡할 수 있지만, 기본적인 개념을 이해하면 쉽게 학습할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 383, 'prompt_tokens': 24, 'total_tokens': 407, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.205992821, 'prompt_time': 0.000536449, 'completion_time': 0.97103913, 'total_time': 0.971575579}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-4f17e697-2d04-414f-8427-2f3693acb854', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--b0ba740e-e7cd-42a4-adef-a5dc34db6a21-0' usage_metadata={'input_tokens': 24, 'output_tokens': 383, 'total_tokens': 407, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델은 다양한 데이터를 수집하여 학습합니다. 이 데이터는 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다.\n",
      "2.  **데이터 전처리**: 수집된 데이터는 전처리 과정을 거칩니다. 이 과정에서는 데이터를 정제하고, 필요한 경우 데이터를 변환하거나 축소하는 작업을 수행합니다.\n",
      "3.  **모델 초기화**: 인공지능 모델은 초기화 과정을 거칩니다. 이 과정에서는 모델의 가중치와 편향이 초기화됩니다.\n",
      "4.  **학습**: 인공지능 모델은 학습 데이터를 사용하여 학습합니다. 이 과정에서는 모델이 데이터를 분석하고, 패턴을 학습하며, 가중치와 편향을 업데이트합니다.\n",
      "5.  **평가**: 학습이 완료되면, 인공지능 모델은 평가 데이터를 사용하여 평가됩니다. 이 과정에서는 모델의 성능을 측정하고, 필요한 경우 모델을 조정합니다.\n",
      "\n",
      "예를 들어, 이미지 분류 모델을 학습하는 경우를 생각해 봅시다. 이 모델은 다양한 이미지 데이터를 수집하여 학습합니다. 이 데이터는 고양이, 강아지, 자동차 등 다양한 객체를 포함할 수 있습니다. 모델은 이 데이터를 분석하여 각 객체를 분류하는 법을 학습합니다. 학습이 완료되면, 모델은 새로운 이미지를 분류할 수 있습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 다음과 같은 핵심 개념을 포함합니다.\n",
      "\n",
      "*   **오차**: 모델의 예측과 실제 값 사이의 차이입니다.\n",
      "*   **손실 함수**: 모델의 성능을 측정하는 함수입니다. 손실 함수는 오차를 최소화하는 것을 목표로 합니다.\n",
      "*   **최적화 알고리즘**: 모델의 가중치와 편향을 업데이트하는 알고리즘입니다. 최적화 알고리즘은 손실 함수를 최소화하는 것을 목표로 합니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 복잡할 수 있지만, 기본적인 개념을 이해하면 쉽게 학습할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 규칙을 발견하고, 대상을 구분하거나 예측할 수 있도록 하는 것이죠.\\n\\n예를 들어, 고양이와 강아지의 사진을 구분하는 모델을 만든다고 가정해 봅시다. \\n\\n1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 모읍니다. 이 사진들이 바로 인공지능이 학습하는 재료가 됩니다.\\n\\n2. **데이터 전처리**: 수집한 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다. \\n\\n3. **모델 훈련**: 고양이 사진에는 \\'고양이\\'라는 레이블을, 강아지 사진에는 \\'강아지\\'라는 레이블을 달아 모델에 입력합니다. 모델은 이 레이블을 보고, 어떤 사진이 고양이인지 강아지인지를 스스로 구분하려고 합니다.\\n\\n4. **오류 수정**: 처음에는 모델이 사진을 제대로 구분하지 못할 것입니다. 이때, 모델이 잘못 분류한 사진에 대해 \"이건 고양이야\", \"이건 강아지야\"라며 정답을 알려줍니다. 이 과정을 통해 모델은 조금씩 사진을 구분하는 법을 배워갑니다.\\n\\n5. **성능 평가**: 일정 횟수 이상 훈련시킨 후, 모델에 새로운 사진을 보여주고 제대로 구분하는지 확인합니다. 이 단계에서 모델의 성능을 평가할 수 있습니다.\\n\\n6. **최적화**: 성능이 만족스럽지 않으면, 모델 구조를 바꾸거나 더 많은 데이터를 추가하는 등 다양한 방법으로 모델을 개선합니다.\\n\\n이렇게 인공지능 모델은 수많은 데이터를 보고, 스스로 규칙을 학습하며, 실제 상황에서 활용할 수 있는 예측이나 분류 능력을 키우게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 346, 'prompt_tokens': 36, 'total_tokens': 382, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.199196249, 'prompt_time': 0.000516243, 'completion_time': 0.844077834, 'total_time': 0.844594077}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-324d55fd-ec80-4e5a-bc50-857447d4a1b5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--e50ca45a-e2b8-4339-a16a-b4fce5e3fa92-0' usage_metadata={'input_tokens': 36, 'output_tokens': 346, 'total_tokens': 382, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 규칙을 발견하고, 대상을 구분하거나 예측할 수 있도록 하는 것이죠.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 구분하는 모델을 만든다고 가정해 봅시다. \n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 모읍니다. 이 사진들이 바로 인공지능이 학습하는 재료가 됩니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다. \n",
      "\n",
      "3. **모델 훈련**: 고양이 사진에는 '고양이'라는 레이블을, 강아지 사진에는 '강아지'라는 레이블을 달아 모델에 입력합니다. 모델은 이 레이블을 보고, 어떤 사진이 고양이인지 강아지인지를 스스로 구분하려고 합니다.\n",
      "\n",
      "4. **오류 수정**: 처음에는 모델이 사진을 제대로 구분하지 못할 것입니다. 이때, 모델이 잘못 분류한 사진에 대해 \"이건 고양이야\", \"이건 강아지야\"라며 정답을 알려줍니다. 이 과정을 통해 모델은 조금씩 사진을 구분하는 법을 배워갑니다.\n",
      "\n",
      "5. **성능 평가**: 일정 횟수 이상 훈련시킨 후, 모델에 새로운 사진을 보여주고 제대로 구분하는지 확인합니다. 이 단계에서 모델의 성능을 평가할 수 있습니다.\n",
      "\n",
      "6. **최적화**: 성능이 만족스럽지 않으면, 모델 구조를 바꾸거나 더 많은 데이터를 추가하는 등 다양한 방법으로 모델을 개선합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 수많은 데이터를 보고, 스스로 규칙을 학습하며, 실제 상황에서 활용할 수 있는 예측이나 분류 능력을 키우게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에 고양이와 강아지의 사진을 여러 장 보여 주고, 이것이 고양이인지 강아지인지를 알려주면 모델은 이 정보를 통해 스스로 학습합니다.\n",
      "\n",
      "모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 다양한 고양이와 강아지의 사진을 수집합니다.\n",
      "2. **데이터 입력**: 수집한 사진을 모델에 입력합니다.\n",
      "3. **예측**: 모델은 입력된 사진을 보고 이것이 고양이인지 강아지인지를 예측합니다.\n",
      "4. **오차 계산**: 모델의 예측과 실제 고양이/강아지 여부가 맞지 않을 경우 오차가 발생합니다.\n",
      "5. **모델 업데이트**: 모델은 오차를 줄이기 위해 스스로를 업데이트합니다. 즉, 모델의 내부 파라미터를 조정하여 다음번에 더 정확한 예측을 할 수 있도록 합니다.\n",
      "6. **반복**: 2~5번의 과정을 여러 번 반복합니다.\n",
      "\n",
      "이 과정을 통해 모델은 고양이와 강아지의 특징을 스스로 학습하고, 결국에는 새로운 사진을 봤을 때 그것이 고양이인지 강아지인지를 높은 정확도로 분류할 수 있게 됩니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용되며, 이를 통해 컴퓨터는 데이터를 분석하고, 패턴을 인식하며, 예측을 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터가 데이터를 통해 배우고, 데이터를 기반으로 예측이나 판단을 내리는 과정을 거칩니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다.\n",
      "2. **데이터 준비**: 이 사진들을 컴퓨터가 처리할 수 있도록 숫자의 형태로 변환합니다.\n",
      "3. **모델 초기화**: 모델에게 고양이와 강아지 사진을 구분하는 법을 처음부터 알려주지는 않습니다. 대신, 모델은 처음에 무작위로 가중치를 설정합니다.\n",
      "4. **학습**: 수집한 사진들을 모델에 보여주고, 모델에게 \"이 사진은 고양이인가요, 강아지인가요?\"라고 물어봅니다. 모델은 현재의 가중치를 기반으로 답변을 내놓습니다. \n",
      "5. **오차 계산**: 모델의 답변과 실제 정답(고양이 또는 강아지)을 비교하여 오차를 계산합니다. \n",
      "6. **가중치 업데이트**: 오차를 줄이기 위해 모델은 가중치를 조금씩 조정합니다. 이 과정은 역전파(backpropagation)라고 하며, 모델은 이 과정을 통해 올바른 분류를 위해 필요한 특징들을 스스로 학습합니다.\n",
      "7. **반복**: 4~6번의 과정을 수많은 사진들에 대해 반복합니다. 반복할수록 모델의 정확도가 높아집니다.\n",
      "\n",
      "이렇게 모델은 데이터를 통해 학습하고, 주어진 문제에 대해 더 나은 예측을 할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약 ( 잘 동작하지 않는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**《쇼생크 탈출》**(The Shawshank Redemption, 1994)을 꼽고 싶습니다.  \n",
      "감옥이라는 극한의 공간에서 희망·우정·자유를 그린 작품으로, 드라마 장르의 정수라 할 수 있죠. 처음엔 잔잔하게 흘러가다가 마지막 20분간의 여운이 폭발적으로 다가와 여러 번 돌려보게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002B571C1AE40>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B571DAFF20>, root_client=<openai.OpenAI object at 0x000002B571DE7770>, root_async_client=<openai.AsyncOpenAI object at 0x000002B571DE7890>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002B571C1AE40>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B571DAFF20>, root_client=<openai.OpenAI object at 0x000002B571DE7770>, root_async_client=<openai.AsyncOpenAI object at 0x000002B571DE7890>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **버닝**\n",
      "\n",
      "버닝  \n",
      "감독: 이창동  \n",
      "출연: 유아인, 전종서, 스티븐 연  \n",
      "줄거리: 딥플러스 타격을 맡은 종수는 어릴 친구 해미의 우연한 재회로 그녀와 벤이라는 남자를 만난다. 해미가 아프리카 여행에서 알게 된 벤은 신비로우면서도 부유한 계층의 냄새를 풍기고, 종수는 그와 해미 사이의 관계에 점점 불안과 의심을 키운다. 어느 날 해미가 사라지고, 종수는 벤을 쫓으며 진실을 마주하게 되는데…\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경 ( 잘 동작하는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('**그녀의 이름은 카네키**  \\n'\n",
      " '일본, 2018  \\n'\n",
      " '\\n'\n",
      " '감독: 카니에시로 다케시  \\n'\n",
      " '출연: 요시타카 유라코, 마츠다 쇼타  \\n'\n",
      " '\\n'\n",
      " '20년 전 갑작스레 사라진 ‘카네키 유카’—그녀의 시신이 한 외딴 진창에서 발굴된다.  \\n'\n",
      " '사건 당일, 그녀와 함께 있었던 네 남자(첫사랑·형·전 남편·동료 형사)는 각자의 입장에서 진실을 숨기고 살아왔다.  \\n'\n",
      " '유카의 남동생 ‘타케루’는 형사가 되어 그들을 추적하지만, 과거를 파헤칠수록 죽은 자가 아닌 산 자들의 상처가 드러난다.  \\n'\n",
      " '과거와 현재가 교차하는 조사 끝에 드러나는 단 한 줄의 유언,  \\n'\n",
      " '그 말 한마디가 네 남자의 20년간의 거짓과 자책, 그리고 ‘사랑’의 진짜 뜻을 뒤바꾼다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
